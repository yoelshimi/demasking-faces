{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Objective: Main aim of this notebook is to generate face behind the mask using autoencoder."},{"metadata":{},"cell_type":"markdown","source":"## Import Necessary Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras as keras\nfrom keras.layers import Dense, Conv2D, MaxPool2D, UpSampling2D, Dropout, Input\nfrom keras.preprocessing.image import img_to_array\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tqdm import tqdm \nimport numpy as np\nimport os\nimport re\nfrom skimage.measure import compare_ssim\nfrom scipy import ndimage\nimport random\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tf.__version__)\nprint(keras.__version__)\nprint(np.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.engine import  Model\nfrom keras.layers import Input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install image-quality\nimport imquality.brisque as brisque","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load data\nHere I am going to load only 2500 images each with mask and no mask. These images are converted to an array and are appended in empty array. Here I also have defind function to load data serially. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# to get the files in proper order\ndef sorted_alphanumeric(data):  \n    convert = lambda text: int(text) if text.isdigit() else text.lower()\n    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n    return sorted(data,key = alphanum_key)\n\n\n# defining the size of image \nSIZE = 256\n\nmask_path = '../input/face-mask-lite-dataset/with_mask'\nmask_array = []\n\nimage_path = '../input/face-mask-lite-dataset/without_mask'\nimg_array = []\n\nimage_file = sorted_alphanumeric(os.listdir(image_path))\nmask_file = sorted_alphanumeric(os.listdir(mask_path))\n\n        \nfor i in tqdm(image_file):\n \n    if i == 'seed1000.png':\n        break\n    \n    else:\n        image = cv2.imread(image_path + '/' + i,1)\n\n        # as opencv load image in bgr format converting it to rgb\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        # resizing images \n        image = cv2.resize(image, (SIZE, SIZE))\n\n        # normalizing image \n        image = image.astype('float32') / 255.0\n        # appending normal sketch image\n        img_array.append(img_to_array(image))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in tqdm(mask_file):\n    if i == 'with-mask-default-mask-seed1000.png':\n        break\n    else:    \n        image = cv2.imread(mask_path + '/' + i,1)\n\n          # as opencv load image in bgr format converting it to rgb\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        # resizing images \n        image = cv2.resize(image, (SIZE, SIZE))\n\n        # normalizing image \n        image = image.astype('float32') / 255.0\n\n        #appending normal normal image    \n        mask_array.append(img_to_array(image))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot image pair"},{"metadata":{},"cell_type":"markdown","source":"## Slicing and reshaping\nHere i have used 2300 images for training and remaining 200 for testing."},{"metadata":{"trusted":true},"cell_type":"code","source":"n = int(len(mask_array)*0.8)\ntrain_mask_image = mask_array[:n]\ntrain_image = img_array[:n]\ntest_mask_image = mask_array[n:]\ntest_image = img_array[n:]\n\n# reshaping\ntrain_mask_image = np.reshape(train_mask_image,(len(train_mask_image),SIZE,SIZE,3))\ntrain_image = np.reshape(train_image, (len(train_image),SIZE,SIZE,3))\nprint('Train no mask image shape:',train_image.shape)\ntest_mask_image = np.reshape(test_mask_image,(len(test_mask_image),SIZE,SIZE,3))\ntest_image = np.reshape(test_image, (len(test_image),SIZE,SIZE,3))\nprint('Test no mask image shape',test_image.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if 0:\n    mask_region = [i==r for (i,r) in zip(mask_array, img_array)]\n\n    mask_region = [tf.reduce_all(x,axis=2) for x in mask_region]\n    mask_region = [tf.stack([tf.logical_not(x),x],axis=2) for x in mask_region]\n    mask_region_float = tf.reshape([tf.reshape(m,(SIZE,SIZE,2)) for m in mask_region], (len(mask_region),SIZE,SIZE,2))\n\n\n    print(img_array[0][:,:,1] - tf.cast(mask_region_float[0,:,:,1],dtype='float'))\n    plt.imshow(img_array[0][:,:,0] -  tf.cast(mask_region_float[0,:,:,1],dtype='float'))\n    plt.show()\n    print(mask_region_float.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\ntrain_mask_image.shape\nprint(mask_region_float.shape)\nmask_region_tr = mask_region_float[:800,:,:,:]\nmask_region_te = mask_region_float[800:,:,:,:]\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"image editing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def blurImage(im):\n    k = random.randint(1,3)\n    k = k * 2 + 1\n    res = cv2.GaussianBlur(im,(k,k),0)\n    return res\n\ndef medFilt(im):\n    res = np.uint8(im*256)\n    res = cv2.medianBlur(res,5)\n    return res\n\ndef rotImage(im):   \n    #rotation angle in degree\n    (h, w) = im.shape[:2]\n    (cX, cY) = (w // 2, h // 2)\n    deg = random.random() - 0.5\n    isflip = random.random()\n    M = cv2.getRotationMatrix2D((cX, cY), 20*deg, 1.0)\n    res = cv2.warpAffine(im, M, (w, h))\n    \n    if isflip>0.5:\n        res = flipImage(res)\n    return res\n\ndef flipImage(im):\n    res = np.fliplr(im)\n    return res\n\ndef saltPImage(im):\n    (h, w) = image.shape[:2]\n    sc = random.random()\n    m = np.random.normal(scale=sc/2,size = (h,w,3))\n    res = im + m\n    return res\n\ndef shotNoise(im):\n    (h, w) = image.shape[:2]\n    rng = np.random.default_rng()\n    sc = random.random() / 10\n    s = rng.poisson(sc, (h,w,3)) - sc\n    res = im + s\n    return res\n\ndef darkenIm(im):\n    factor = random.random()\n    res = im * (0.5+factor/2)\n    return res\n\ndef brightenIm(im):\n    factor = random.random()\n    factor = factor / 2 + 0.5\n    res = im / factor\n    return res\n\ndef changeColour(im):\n    order = np.random.permutation(range(3))\n    res = im[:,:,[order[0], order[1], order[2]]]\n    return res\n\ndef edit_images(mask_array):\n    mask_array_edit = mask_array.copy()\n    for iter in range(3):\n        for ind in tqdm(range(len(mask_array))):\n            im = mask_array_edit[ind]\n            alg = random.random()\n            if alg < 0.1:\n                res = im\n            elif alg < 0.2 and alg > 0.1:\n                res = blurImage(im)\n                res = im\n            elif alg < 0.3 and alg > 0.2:\n                # res = medFilt(im)\n                res = im\n            elif alg < 0.4 and alg > 0.3:\n                res = rotImage(im)\n            elif alg < 0.5 and alg > 0.4:\n                res = saltPImage(im)\n            elif alg < 0.6 and alg > 0.5:\n                res = changeColour(im)\n            elif alg < 0.7 and alg > 0.6:\n                res = darkenIm(im)\n            elif alg < 0.8 and alg > 0.7:\n                res = shotNoise(im)\n            elif alg < 0.9 and alg > 0.8:\n                res = im\n                res = brightenIm(im)\n            else:\n                res = flipImage(im)\n            mask_array_edit[ind] = res\n    n = int(np.round(len(mask_array_edit)*0.8))\n    mask_array_edit_tr = mask_array_edit[:n]\n    mask_array_edit_te = mask_array_edit[n:]\n\n    mask_array_edit_tr = np.reshape(mask_array_edit_tr,(len(mask_array_edit_tr),SIZE,SIZE,3))\n    print('Train no mask image shape:',mask_array_edit_tr.shape)\n\n    mask_array_edit_te = np.reshape(mask_array_edit_te,(len(mask_array_edit_te),SIZE,SIZE,3))\n    print('Test no mask image shape',mask_array_edit_te.shape)\n    return mask_array_edit_tr,mask_array_edit_te, mask_array_edit\n\nmask_array_edit_tr,mask_array_edit_te, mask_array_edit = edit_images(mask_array)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_image_pair(images = 5):\n    for i in range(images):\n        plt.figure(figsize = (7,7))\n        plt.subplot(1,3,1)\n        plt.title(\"No Mask\", fontsize = 15)\n        plt.imshow(img_array[i].reshape(SIZE, SIZE, 3))\n        plt.subplot(1,3,2)\n        plt.title(\"Mask\", fontsize = 15)\n        plt.imshow(mask_array[i].reshape(SIZE, SIZE, 3))\n        plt.subplot(1,3,3)\n        plt.title(\"Mask\", fontsize = 15)\n        plt.imshow(mask_array_edit[i].reshape(SIZE, SIZE, 3))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_image_pair(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining our model"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_input = keras.Input(shape=(SIZE,SIZE, 3), name=\"img\")\nx = Conv2D(filters = 16, kernel_size = (3,3), activation = 'relu', padding = 'same')(encoder_input)\nx = MaxPool2D(pool_size = (2,2))(x)\n\nx = Conv2D(filters = 32,kernel_size = (3,3),strides = (2,2), activation = 'relu', padding = 'valid')(x)\nx = Conv2D(filters = 64, kernel_size = (3,3), strides = (2,2), activation = 'relu', padding = 'same')(x)\nx = MaxPool2D(pool_size = (2,2))(x)\n\nx = Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\nx = Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\nx = Conv2D(filters = 128 , kernel_size = (3,3), activation = 'relu', padding = 'same')(x) \nx = Conv2D(filters = 256 , kernel_size = (3,3), activation = 'relu', padding = 'same')(x) \nencoder_output = Conv2D(filters = 512 , kernel_size = (3,3), activation = 'relu', padding = 'same')(x) \nencoder = tf.keras.Model(encoder_input, encoder_output)\n\ndecoder_input = Conv2D(filters = 512 ,kernel_size = (3,3), activation = 'relu', padding = 'same')(encoder_output)\nx = UpSampling2D(size = (2,2))(decoder_input)\nx = Conv2D(filters = 256, kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\nx = Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\nx = Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\nx = Conv2D(filters = 164, kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\nx = UpSampling2D(size = (2,2) )(x)\n\nx = Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\nx = UpSampling2D(size = (2,2) )(x)\nx = Conv2D(filters = 32 , kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\nx = UpSampling2D(size = (2,2) )(x)\n \nx = Conv2D(filters = 16  , kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\ndecoder_output = Conv2D(filters = 3, kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\n\n# final model\nmodel = keras.Model(encoder_input, decoder_output)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nencoder_input = keras.Input(shape=(SIZE,SIZE, 3), name=\"img\")\nx = Conv2D(filters = 16, kernel_size = (3,3), activation = 'relu', padding = 'same')(encoder_input)\nx = MaxPool2D(pool_size = (2,2))(x)\n\nx = Conv2D(filters = 32,kernel_size = (3,3),strides = (2,2), activation = 'relu', padding = 'valid')(x)\nx = Conv2D(filters = 64, kernel_size = (3,3), strides = (2,2), activation = 'relu', padding = 'same')(x)\nx = MaxPool2D(pool_size = (2,2))(x)\n\nx = Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\nx = Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\nx = Conv2D(filters = 128 , kernel_size = (3,3), activation = 'relu', padding = 'same')(x) \nx = Conv2D(filters = 256 , kernel_size = (3,3), activation = 'relu', padding = 'same')(x) \nencoder_output = Conv2D(filters = 512 , kernel_size = (3,3), activation = 'relu', padding = 'same')(x) \nencoder = tf.keras.Model(encoder_input, encoder_output)\n\ndecoder_input = Conv2D(filters = 512 ,kernel_size = (3,3), activation = 'relu', padding = 'same')(encoder_output)\nx = UpSampling2D(size = (2,2))(decoder_input)\nx = Conv2D(filters = 256, kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\nx = Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\nx = Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\nx = Conv2D(filters = 164, kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\nx = UpSampling2D(size = (2,2) )(x)\n\nx = Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\nx = UpSampling2D(size = (2,2) )(x)\nx = Conv2D(filters = 32 , kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\nx = UpSampling2D(size = (2,2) )(x)\n \nx = Conv2D(filters = 16  , kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\ndecoder_output = Conv2D(filters = 2, kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\n\n# final model\nmaskModel = keras.Model(encoder_input, decoder_output)\nmaskModel.summary()\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"FOR GAN: defining our descriminator:"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n# define the discriminator model\ndef define_discriminator(image_shape):\n\t# weight initialization\n\tinit = RandomNormal(stddev=0.02)\n\t# source image input\n\tin_src_image = Input(shape=image_shape)\n\t# target image input\n\tin_target_image = Input(shape=image_shape)\n\t# concatenate images channel-wise\n\tmerged = Concatenate()([in_src_image, in_target_image])\n\t# C64\n\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n\td = LeakyReLU(alpha=0.2)(d)\n\t# C128\n\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n\td = BatchNormalization()(d)\n\td = LeakyReLU(alpha=0.2)(d)\n\t# C256\n\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n\td = BatchNormalization()(d)\n\td = LeakyReLU(alpha=0.2)(d)\n\t# C512\n\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n\td = BatchNormalization()(d)\n\td = LeakyReLU(alpha=0.2)(d)\n\t# second last output layer\n\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n\td = BatchNormalization()(d)\n\td = LeakyReLU(alpha=0.2)(d)\n\t# patch output\n\td = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n\tpatch_out = Activation('sigmoid')(d)\n\t# define model\n\tmodel = Model([in_src_image, in_target_image], patch_out)\n\t# compile model\n\topt = Adam(lr=0.0002, beta_1=0.5)\n\tmodel.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n\treturn model\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Compiling our model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a loss\ndef myLoss(im,ref):\n    mse = keras.losses.mean_squared_error(im,ref)\n    score = tf.image.ssim_multiscale(im, ref,1,filter_sigma=0.75)\n    return tf.reduce_mean(mse) * (tf.abs(1-score[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.shape(train_image)\n#prediction = maskModel.predict(mask_array[0].reshape(1,SIZE, SIZE, 3))\n#plt.imshow(np.squeeze(prediction))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nmaskModel.compile(optimizer = keras.optimizers.Adam(learning_rate = 0.001), \n                  loss = keras.losses.categorical_crossentropy,\n              metrics = 'acc')\n\n\nmaskModel.fit(train_image, mask_region_tr, epochs = 10)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    print(train_image[0].shape) \n    prediction = model.predict(tf.reshape(train_image[1],(-1,256,256,3)))\n    plt.imshow(tf.squeeze(prediction))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_image.dtype)\ndef plot_images(start = 0, end = 5):\n    #  os.mkdir('/kaggle/working/comps')\n    for i in range(start, end, 1):\n        plt.figure(figsize = (10,10))\n        plt.subplot(1,3,1)\n        plt.title(\"No Mask\", fontsize = 12)\n        plt.imshow(test_image[i])\n        plt.subplot(1,3,2)\n        plt.title(\"Mask\", fontsize = 12)\n        plt.imshow(mask_array_edit_te[i])\n        plt.subplot(1,3,3)\n        plt.title(\"Predicted\", fontsize = 12)\n        prediction = model.predict(tf.reshape(tf.keras.backend.constant(mask_array_edit_te[i]),\n                                              (-1,256,256,3)))\n        plt.imshow(tf.squeeze(prediction))\n        \n        #  plt.savefig('comps'+os.sep+'test img:'+str(i)+'.tiff')\n        plt.show()\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'mse',\n              metrics = ['acc'])\nresults=[]\n\nfor iter in range(5):\n    mask_array_edit_tr,mask_array_edit_te,mask_array_edit = edit_images(mask_array)\n    model.fit(mask_array_edit_tr, train_image, epochs = 15,shuffle='True',validation_split = 0.2)\n    plot_images(21,25)\n    results.append(model.evaluate(mask_array_edit_te, test_image, batch_size=32))\n    print(\"test loss, test acc:\", results[iter])\n    print(\"----\"+str(iter)+\"-----\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_acc= model.evaluate(test_mask_image, test_image)\nprint(\"Loss: \",loss_acc[0])\nprint('Accuracy: ', np.round(loss_acc[1],2) * 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**discriminator**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nvgg_disc = VGG16(include_top=0,input_shape=(256,256,3),classes=1000) # real, fake\nprint(vgg_disc.summary())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg_out_shape = (8,8,512)\n\nfor layer in vgg_disc.layers[:]:\n    layer.trainable = False\n    \ndiscriminator = keras.Sequential()\n\n# Add the vgg convolutional base model\ndiscriminator.add(vgg_disc)\n# Add new layers\ndiscriminator.add(keras.layers.Flatten())\ndiscriminator.add(Dense(128, activation='relu'))\ndiscriminator.add(Dropout(0.5))\ndiscriminator.add(Dense(2, activation='softmax'))\n# Show a summary of the model. Check the number of trainable parameters\ndiscriminator.summary()\n\ndiscriminator.compile(loss='mae',\n              optimizer=keras.optimizers.Adam(lr=1e-6),\n              metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.vgg16 import preprocess_input\n# prepare the image for the VGG model\nim = tf.reshape(preprocess_input(train_image[0]),(-1,256,256,3))\n\nyhat = discriminator.predict(im)\nprint(yhat)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"training of discriminator"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(mask_array_edit))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gen_images = np.zeros((len(mask_array_edit),SIZE,SIZE,3))\nfor i in tqdm(range(len(mask_array_edit))):\n    gen_images[i,:,:,:] = np.reshape(model.predict(tf.reshape(mask_array_edit[i],\n                                                              (1,SIZE,SIZE,3))),(1,SIZE,SIZE,3))       \n\ngen_images = tf.Variable(gen_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ims_tf = tf.Variable(np.reshape(train_image,(-1,256,256,3)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(10):\n    plt.imshow(test_image[i])\n    plt.show()\n    plt.imshow(gen_images[len(train_image) + i])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tf.shape(gen_images))\nprint(tf.shape(train_ims_tf)) # list of tensors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"disc_data = tf.concat([tf.cast(gen_images,dtype='float32'), tf.cast(train_ims_tf,dtype='float32')],0)\nprint(tf.shape(disc_data))\nnims = tf.shape(gen_images)[0]\nnims2 = tf.shape(train_ims_tf)[0]\n\ndisc_tags = tf.concat([tf.concat([tf.zeros((nims,1),dtype='int32'),tf.ones((nims,1),dtype='int32')],1), \n             tf.concat([tf.ones((nims2,1),dtype='int32'),tf.zeros((nims2,1),dtype='int32')],1)],0)\nprint(disc_tags[0])\nprint(disc_tags[1500])\nprint(tf.shape(disc_tags))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator.fit(disc_data, disc_tags,batch_size=64,epochs=10, validation_split = 0.2,shuffle='True')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test the discriminator"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\nfor i in tqdm(range(tf.shape(gen_images)[0])):\n    preds.append(discriminator(tf.reshape(gen_images[i],(-1,256,256,3))))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = np.asarray(preds)\nvals = np.argsort(-preds[:,0][:,0])\nprint(vals[0:4])\n\nfor iter in range(20):\n    plt.figure()\n    plt.subplot(1,2,1)\n    plt.imshow(gen_images[vals[iter]])\n    plt.title(preds[vals[iter]])\n    plt.subplot(1,2,2)\n    if vals[iter] < len(train_image):\n        plt.imshow(train_image[vals[iter]])\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"finally, train our model with discriminator as loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"def discLoss(img,truth):\n    res1 = discriminator(img)\n    res2 = discriminator(truth)\n    res3 = keras.losses.MSE(img,truth)\n    return tf.norm(res1-res2)*0.2 + res3*0.8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def brisqueLoss(img, truth):\n    res1 = brisque.score(tf.make_ndarray(img))\n    res2 = brisque.score(tf.make_ndarray(truth))\n    res3 = keras.losses.MSE(img,truth)\n    return abs(res1-res2)*0.2 + res3*0.8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ssimLoss(img,truth):\n    res1 = tf.image.ssim_multiscale(img,truth,255)\n    res3 = keras.losses.MSE(img,truth)\n    return 1e3*(1-res1)*0.2 + res3*0.8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def psnrLoss(img,truth):\n    res1 = tf.image.psnr(img,truth,255)\n    res2 = tf.image.ssim_multiscale(img,truth,255)\n    return 10/res1*0.2 + 1e3*(1-res2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in discriminator.layers[:]:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"try to train a new generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"from copy import copy\neditor = copy(model)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"editor.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-5), \n               loss = 'mse', metrics = ['acc']) \ngen_train = np.array(gen_images[0:500]) \ntrain_ims_tf2 = np.array(train_ims_tf[0:500])\neditor.fit(gen_train, train_ims_tf2, epochs = 5,validation_split = 0.2,shuffle='True')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for iter in range(20):\n\n    if vals[iter] < len(train_image):\n        plt.figure()\n        plt.subplot(1,2,1)\n        plt.imshow(tf.squeeze(editor(tf.reshape(gen_images[vals[iter]],(-1,256,256,3))) ))\n        plt.title(preds[vals[iter]])\n        plt.subplot(1,2,2)\n        plt.imshow(train_image[vals[iter]])\n        plt.show()\n    print(editor(tf.reshape(gen_images[vals[iter]],(-1,256,256,3))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if True:\n    for iter in range(10):\n        mask_array_edit_tr,mask_array_edit_te,mask_array_edit = edit_images(mask_array)\n        \n        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-6), loss = psnrLoss,\n                  metrics = ['acc'])\n        model.fit(mask_array_edit_tr, train_image, epochs = 5,shuffle='True',validation_split = 0.2)\n        \n        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-6), loss = discLoss,\n                     metrics = ['acc'])\n        model.fit(mask_array_edit_tr, train_image, epochs = 5,shuffle='True',validation_split = 0.2, \n                  batch_size=16)\n        \n        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-5), loss = 'mse',\n                  metrics = ['acc'])\n        model.fit(mask_array_edit_tr, train_image, epochs = 5,validation_split = 0.2,shuffle='True')\n        plot_images(50,55)\n    plot_images(20,30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## plotting images"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_images(start = 0, end = 5):\n    for i in range(start, end, 1):\n        plt.figure(figsize = (10,10))\n        plt.subplot(1,3,1)\n        plt.title(\"No Mask\", fontsize = 12)\n        plt.imshow(test_image[i])\n        plt.subplot(1,3,2)\n        plt.title(\"Mask\", fontsize = 12)\n        plt.imshow(test_mask_image[i])\n        plt.subplot(1,3,3)\n        plt.title(\"Predicted\", fontsize = 12)\n        prediction = model.predict(test_mask_image[i].reshape(1,SIZE, SIZE, 3)).reshape(SIZE, SIZE, 3)\n        plt.imshow(prediction)\n        plt.show()\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_images(5,12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n'''\nmask_path = '../input/toker2/'\nmask_array = []\n\n\nmask_file = sorted_alphanumeric(os.listdir(mask_path))\nfor i in tqdm(mask_file):\n    image = cv2.imread(mask_path + '/' + i,1)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (SIZE, SIZE))\n    image = image.astype('float32') / 255.0\n    mask_array.append(img_to_array(image))\n    \n'''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_image_pair(images = 1):\n    for i in range(images):\n        plt.figure(figsize = (7,7))\n        plt.subplot(1,2,1)\n        plt.title(\"Mask\", fontsize = 15)\n        plt.imshow(mask_array[i].reshape(SIZE, SIZE, 3))\n        plt.subplot(1,2,2)\n        plt.title(\"NO Mask\", fontsize = 15)\n        plt.imshow(model.predict(mask_array[i].reshape(1,SIZE, SIZE, 3)).reshape(SIZE, SIZE, 3))\n\n        \n        \n        \nplot_image_pair(7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if 0:\n    import os\n    os.chdir(r'/kaggle/working/comps')\n    print(os.listdir())\n    import shutil\n    shutil.make_archive('comparison', 'zip', os.getcwd())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if  0: \n    from IPython.display import FileLink\n    FileLink(r'./comparison.zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(mask_array[0].reshape(1,SIZE, SIZE, 3)).reshape(SIZE, SIZE, 3)\nplt.imshow(prediction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Thanks for your visit"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}