{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16 discriminator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Pxy1L764pkE"
      },
      "source": [
        "Code for using VGG16 network as quality metric for our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_JrwQFl2_fv"
      },
      "source": [
        "discriminator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RixAlbn34oNw"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k67emIOV3DLX"
      },
      "source": [
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "vgg_disc = VGG16(include_top=0,input_shape=(256,256,3),classes=1000) # real, fake\n",
        "print(vgg_disc.summary())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVYiDT8c3INg"
      },
      "source": [
        "create discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8RFxGTW3K_x"
      },
      "source": [
        "vgg_out_shape = (8,8,512)\n",
        "​\n",
        "for layer in vgg_disc.layers[:]:\n",
        "    layer.trainable = False\n",
        "    \n",
        "discriminator = keras.Sequential()\n",
        "​\n",
        "# Add the vgg convolutional base model\n",
        "discriminator.add(vgg_disc)\n",
        "# Add new layers\n",
        "discriminator.add(keras.layers.Flatten())\n",
        "discriminator.add(Dense(128, activation='relu'))\n",
        "discriminator.add(Dropout(0.5))\n",
        "discriminator.add(Dense(2, activation='softmax'))\n",
        "# Show a summary of the model. Check the number of trainable parameters\n",
        "discriminator.summary()\n",
        "​\n",
        "discriminator.compile(loss='mae',\n",
        "              optimizer=keras.optimizers.Adam(lr=1e-6),\n",
        "              metrics=['acc'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmIAHP5L3PXO"
      },
      "source": [
        "test initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYRqtqjS3QGv"
      },
      "source": [
        "from keras.applications.vgg16 import preprocess_input\n",
        "# prepare the image for the VGG model\n",
        "im = tf.reshape(preprocess_input(train_image[0]),(-1,256,256,3))\n",
        "​\n",
        "yhat = discriminator.predict(im)\n",
        "print(yhat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7dNST733ZmT"
      },
      "source": [
        "training of discriminator and data generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUMqy8Y13ZYo"
      },
      "source": [
        "print(len(mask_array_edit))\n",
        "\n",
        "gen_images = np.zeros((len(mask_array_edit),SIZE,SIZE,3))\n",
        "for i in tqdm(range(len(mask_array_edit))):\n",
        "    gen_images[i,:,:,:] = np.reshape(model.predict(tf.reshape(mask_array_edit[i],\n",
        "                                                              (1,SIZE,SIZE,3))),(1,SIZE,SIZE,3))       \n",
        "​\n",
        "gen_images = tf.Variable(gen_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrUBKrFx3ieD"
      },
      "source": [
        "train_ims_tf = tf.Variable(np.reshape(train_image,(-1,256,256,3)))\n",
        "for i in range(10):\n",
        "    plt.imshow(test_image[i])\n",
        "    plt.show()\n",
        "    plt.imshow(gen_images[len(train_image) + i])\n",
        "    plt.show()\n",
        "print(tf.shape(gen_images))\n",
        "print(tf.shape(train_ims_tf)) # list of tensors\n",
        "\n",
        "disc_data = tf.concat([tf.cast(gen_images,dtype='float32'), tf.cast(train_ims_tf,dtype='float32')],0)\n",
        "print(tf.shape(disc_data))\n",
        "nims = tf.shape(gen_images)[0]\n",
        "nims2 = tf.shape(train_ims_tf)[0]\n",
        "​\n",
        "disc_tags = tf.concat([tf.concat([tf.zeros((nims,1),dtype='int32'),tf.ones((nims,1),dtype='int32')],1), \n",
        "             tf.concat([tf.ones((nims2,1),dtype='int32'),tf.zeros((nims2,1),dtype='int32')],1)],0)\n",
        "print(disc_tags[0])\n",
        "print(disc_tags[1500])\n",
        "print(tf.shape(disc_tags))\n",
        "\n",
        "discriminator.fit(disc_data, disc_tags,batch_size=64,epochs=10, validation_split = 0.2,shuffle='True')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zyjr05kJ3vLJ"
      },
      "source": [
        "Test the discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47ZiUSdA3w9q"
      },
      "source": [
        "preds = []\n",
        "for i in tqdm(range(tf.shape(gen_images)[0])):\n",
        "    preds.append(discriminator(tf.reshape(gen_images[i],(-1,256,256,3))))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IIO6usP336V"
      },
      "source": [
        "preds = np.asarray(preds)\n",
        "vals = np.argsort(-preds[:,0][:,0])\n",
        "print(vals[0:4])\n",
        "​\n",
        "for iter in range(20):\n",
        "    plt.figure()\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(gen_images[vals[iter]])\n",
        "    plt.title(preds[vals[iter]])\n",
        "    plt.subplot(1,2,2)\n",
        "    if vals[iter] < len(train_image):\n",
        "        plt.imshow(train_image[vals[iter]])\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}